class: center, middle

# Artificial neural networks

.center[
  <img src="./images/TitleSlideImage.png" alt="Title image"
       style="max-width:55%; max-height:45vh; width:auto; height:auto; object-fit:contain; display:block; margin:0 auto;">
]

**Автор:** Петър Герджиков

---

# Programming VS Machine & Deep learning

#### Традиционно програмиране
- Разработчик пише правила/логика ръчно
- Детерминистично – същи входове = същи изходи
- Скалируемост: добра за определени сценарии, лоша при сложност
- Примери: Алгоритми за пространствен анализ, класификация по готови правила

#### Machine Learning / Deep Learning
- Модел **учи** от примери в данните
- Data-driven подход – правилата се издават автоматично
- Скалируемост: висока за повторяващи се задачи с големи датасети
- Примери: Класификация на сателитни изображения, детекция на обекти

#### Преходът към DL в ГИС контекста
- Традиционни методи: многобройни параметри, ръчна настройка
- DL: автоматично извличане на признаци, по-добра генерализация
- **Ключово:** DL е избор, когато имаме достатъчно данни и задачата е сложна

---

# Защо изкуствените невронни мрежи са от интерес в геопространствения анализ?

#### Предизвикателства в традиционния ГИС анализ
- Класификация на сателитни изображения отнема часове ръчна работа
- Извличане на геоспециалиц от растери е деликатно и субективно
- Необходимост за различни подходи при различни мащабове и типове данни

#### Как ИНМ решават тези проблеми
- **Автоматизация:** обучен модел класифицира няколко минути вместо часове
- **Обобщение:** един модел може да работи на различни мащабове
- **Точност:** често по-добра от традиционните методи при достатъчни данни

#### Конкретни примери
- Класификация на земно покритие (LULC) от Sentinel-2/Landsat
- Извличане на сгради и пътна мрежа от HighRes изображения
- Детекция на промени във времето (обезлесяване, урбанизация)
- Картиране на растителност и водни обекти

---

# Цел на курсовата работа и структура

#### Структура на работата

**Първа част: Основи на ИНМ**
- Математически модел на неврона
- Активационни функции
- Feedforward архитектура
- Обучение (loss, gradient descent, backpropagation)

**Втора част: Конволюционни невронни мрежи (CNN)**
- Защо CNN за изображения?
- Конволюционен слой (kernel, stride, padding)
- Pooling слоеве
- Йерархия на признаците
- Примери: класификация на сателитни изрязъци

**Трета част: Семантична сегментация на геопространствени данни**
- Определение и разлика от object detection/instance segmentation
- Архитектури за сегментация (U-Net, DeepLab, SegNet)
- Приложения в ГИС
- Данни и предизвикателства

**Практическа част: CNN проект**
- Реална имплементация с TensorFlow
- Класификация на сателитни изображения

---

# Какво е изкуствена невронна мрежа?

#### Основната идея
- Събираме много прости един елемент (неврон)
- Всеки неврон получава входове, прилага претегляне и активация
- Когато комбинираме хиляди такива елементи, можем да научим **много сложни** зависимости между входове и изходи

#### Биологична аналогия (опростена)
- Биологичен неврон получава сигнали (дендрити), обработва ги и изпраща нов сигнал (аксон)
- Изкуствен неврон работи по подобен начин, но с числа вместо електрохимични импулси
- **Забележка:** това е функционална аналогия, не биологична точност

#### Визуален елемент
- **Изображение:** Диаграма на един простой неврон с входове (x₁, x₂, ...), тегла (w₁, w₂, ...), bias (b) и активационна функция f()

---

# Основни елементи на невронната мрежа

#### Основни компоненти
- **Входове (x₁, x₂, ...):** Данни от външния свят (например пиксели от изображение)
- **Тегла (w₁, w₂, ...):** Параметри, които показват "колко важен" е всеки вход. Това е това, което моделът **учи**
- **Bias (b):** Допълнителен параметър, който позволява гъвкаво изместване на решаващата граница
- **Активационна функция f():** Прилага се след претегления сбор – позволява нелинейност

#### Активационни функции (кратко без формули)
- **Sigmoid:** Стара, популярна; всички стойности между 0 и 1; проблем: малки градиенти при дълбоки мрежи
- **ReLU (Rectified Linear Unit):** Съвременен стандарт; максимум(0, x); бърза за обучение, стабилна
- За геопространствени ИНМ обикновено избираме **ReLU**

#### Обучение (кратко)
- **Loss функция:** Измерва "колко лошо" предсказва моделът (сравнява предсказаното с реалното)
- **Gradient descent:** Алгоритъм, който намалява loss функцията чрез коригиране на теглата в правилната посока
- **Backpropagation:** Алгоритъм, който разпределя грешката назад през мрежата, за да се знае как да се променят теглата

#### Визуален елемент
- **Изображение:** Схема на един неврон с всички компоненти; графика на ReLU vs Sigmoid функции

---

# Feedforward и CNN – защо ни трябват за изображения

#### Feedforward мрежи (напълно свързани слоеве)
- Всеки неврон в един слой е свързан с всеки неврон в следващия слой
- **Подходящи за:** таблични данни, векторни геопространствени атрибути
- **Проблем:** при изображения това означава огромен брой параметри (например 100×100 пиксела = 10,000 входа!)

#### Ограничения при применение на feedforward за изображения
- Огромен брой параметри → медленобучение
- Загубиват се локални пространствени структури (например ръбове, текстури)
- Слабо обобщение при нови данни

#### CNN (Convolutional Neural Networks) – идеята
- Вместо напълно свързани слоеве, използваме **конволюционни слоеве**
- Идеята: използваме малки матрици (kernels), които се движат по изображението
- Това улавя **локални пространствени структури** много по-ефективно
- Намалява брой параметри → по-бързо обучение, по-добра генерализация

#### Защо CNN са перфектни за ГИС
- Растерни данни (сателитни, аерофото) са двумерни структури
- CNN естествено работи с локални зависимости в растерите
- Много по-ефективни от feedforward за този тип данни

#### Визуален елемент
- **Изображение:** Архитектурна диаграма на CNN (entrada → convolutional слоеве → pooling → fully connected → изход)

---

# CNN в геопространствения анализ

#### Защо CNN се подходят за геопространствени данни
- Растерни формати (GeoTIFF, COG) са природно двумерни матрици
- Локални признаци (текстури, ръбове) са критични за класификация земно покритие
- Модели обучени на един регион могат да работят на други региони

#### Ключови концепции
- **Локални рецептивни полета:** Всеки неврон "вижда" малко окно (например 3×3 пиксела), не цялото изображение
  - Позволява улавяне на текстури (мрежа от дърветата), контрасти (граница град/поле)
  
- **Translation invariance:** Обект (например сграда) в горния ляв ъгъл се разпознава по същия начин, като в центъра
  - **Практично:** при обработка на сателитни сцени, обектите са случайно разположени; CNN го обработва еднакво

- **Йерархия на признаците:** Ранните слоеве улавят прости признаци (ръбове), средните – текстури, дълбоките – цели обекти

#### Примери
- Класификация на сателитни 32×32 px patches в категории: "град", "гора", "вода", "селскостопанска земя"
- Всеки patch го преминава през CNN и получава класа

#### Визуален елемент
- **Изображение:** Пример на сателитна сцена (Sentinel-2, Landsat) с три различни типа земно покритие (град, гора, вода); стрелки показват как CNN обработва локални региони

---

# Какво е семантична сегментация?

#### Определение
- **Семантична сегментация:** За всеки пиксел в изображението предсказваме който му съответства клас
- Резултат: **карта** (растер), при която всеки пиксел има етикет (например "град", "гора", "вода", "селскостопанска земя")

#### Сравнение с други задачи (кратко)
- **Класификация на цялото изображение:** един клас за цялото изображение (например "урбанизирана територия") → не е достатъчно за ГИС
- **Object detection:** предсказва ограничителни правоъгълници (bounding boxes) и класове за отделни обекти (например "сграда в координати X") → полезно, но не дава пикселно разделение
- **Instance segmentation:** разделя пиксели по отделни обекти от един клас (например всяка отделна сграда отделно) → полезно за някои задачи, но сложно
- **Семантична сегментация:** всички пиксели от един клас са един обект, неважи от колко отделни сгради са съставени → идеално за LULC карти

#### Практическото значение
- Традиционни ГИС методи: ръчна дигитализация или pixel-by-pixel класификация в ERDAS/ENVI отнема дни
- CNN сегментация: часа или минути за голяма територия

#### Визуален елемент
- **Изображение:** Тройка (или две) примери:
  - Ляво: сателитно изображение (RGB)
  - Дясно: резултат от семантична сегментация (различни цветове за различни класове: червено = град, зелено = гора, синьо = вода и т.н.)

---

# Архитектури за сегментация (U-Net и др.)

#### Encoder–Decoder парадигма
- **Encoder част:** CNN слоеве компресират входното изображение до по-нискоразмерно представяне
  - Целта: изваждане на високо ниво семантична информация (например "това е град")
  - Страната: губим пространствена разделителна способност
  
- **Decoder част:** операции като upsampling или transposed convolutions възстановяват пространствената разделителна способност
  - Целта: да предскажем клас за всеки оригинален пиксел
  - Проблем: декодерът сам по себе си "видя" низко ниво информация, детайлите се губят

#### U-Net архитектура (специален случай на encoder–decoder)
- **Skip connections:** Директни връзки от encoder към decoder на съответните нива
  - Позволяват комбиниране на высоко-нивелна семантика (от дълбоките encoder слоеве) с детайлна информация (от ранните encoder слоеве)
  - Резултат: много по-добра локализация на границите между класовете
  
- **Форма:** Диаграмата прилича на "U" (отодето и името)
- **Оригинално за:** медицински изображения; показало се отличното и за геопространствени данни
- **Предимство:** баланс между семантична точност и пространствена прецизност

#### Други архитектури (кратко)
- **DeepLab:** Използва atrous (dilated) convolutions и multi-scale контекст; по-мощна, но и по-сложна
- **SegNet:** Опростена версия на encoder–decoder; по-лека за развръщане

#### Личен избор за този проект
- Избрал си U-Net, защото е достатъчно мощна и по-лесна за имплементация vs DeepLab
- Показало се отлично на различни типове геопространствени данни

#### Визуален елемент
- **Изображение:** Архитектурна диаграма на U-Net (encoder с кръгчета и стрелки вляво, decoder вдясно, skip connections между тях, самата форма прилича на "U")